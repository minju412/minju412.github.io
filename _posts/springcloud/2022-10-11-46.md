---
title:  "[E-commerce App] `order-service` 수정 - Orders Kafka Topic "

categories:
  - SpringCloud
tags:
  - [SpringCloud]

toc: true
toc_sticky: true
 
date: 2022-10-11 23:26:00
last_modified_at: 2022-10-11 23:26:03
---

토픽에 정보를 넣는 것 만으로 db에 데이터를 insert 하기 위해서는, 꼭 아래와 같은 JSON 형태로 넣어야 했다.<br>
![스크린샷 2022-10-12 오전 12 01 29](https://user-images.githubusercontent.com/59405576/195128020-d5377e1b-d73d-4abb-b55c-dc4287ca7f8b.png){: width="500" height="500"}<br>
이를 java 코드로 바꾸면 아래와 같다.<br><br>
![스크린샷 2022-10-11 오후 11 45 17](https://user-images.githubusercontent.com/59405576/195123300-1c63944b-ea91-482d-b482-b4c00ea334e8.png){: width="800" height="800"}<br>
위 사진에서처럼 `schema`와 `payload`를 각각 객체로 만들고,<br>
이들을 담고 있는 `dto` 객체를 하나 만들자.<br>
세부적으로는, `schema`를 구성하고 있는 구성 요소 중 `fields`는 리스트 형태로 되어있기 때문에, `field` 객체도 따로 만들자.<br><br>
따라서 총 4개의 dto 를 만들 것이다.
- `KafkaOrderDto`
- `Schema`
- `Field`
- `Payload`

# `order-service`
## 🗂 `dto`
### `KafkaOrderDto.java`
```java
@Data
@AllArgsConstructor
public class KafkaOrderDto implements Serializable {

    private Schema schema;
    private Payload payload;
}
```

### `Schema.java`
```java
@Data
@Builder
public class Schema {

    private String type;
    private List<Field> fields;
    private boolean optional;
    private String name;
}
```

### `Field.java`
```java
@Data
@AllArgsConstructor
public class Field {

    private String type;
    private boolean optional;
    private String field;
}
```

### `Payload.java`
```java
@Data
@Builder
public class Payload {

    private String order_id;
    private String user_id;
    private String product_id;
    private int qty;
    private int unit_price;
    private int total_price;
}
```

이제 이 dto 들을 사용할 수 있는 message 클래스를 만들자.

## 🗂 `messagequeue`
### `OrderProducer.java`
```java
@Service
@Slf4j
public class OrderProducer {
    private KafkaTemplate<String, String> kafkaTemplate;

    List<Field> fields = Arrays.asList(
        new Field("string", true, "order_id"),
        new Field("string", true, "user_id"),
        new Field("string", true, "product_id"),
        new Field("int32", true, "qty"),
        new Field("int32", true, "unit_price"),
        new Field("int32", true, "total_price")
        );

    Schema schema = Schema.builder()
        .type("struct")
        .fields(fields)
        .optional(false)
        .name("orders")
        .build();

    @Autowired
    public OrderProducer(KafkaTemplate<String, String> kafkaTemplate) {
        this.kafkaTemplate = kafkaTemplate;
    }

    public OrderDto send(String topic, OrderDto orderDto) {

        Payload payload = Payload.builder()
            .order_id(orderDto.getOrderId())
            .user_id(orderDto.getUserId())
            .product_id(orderDto.getProductId())
            .qty(orderDto.getQty())
            .unit_price(orderDto.getUnitPrice())
            .total_price(orderDto.getTotalPrice())
            .build();

        // 토픽에 전달할 객체 생성
        KafkaOrderDto kafkaOrderDto = new KafkaOrderDto(schema, payload);

        ObjectMapper mapper = new ObjectMapper();
        String jsonInString = "";
        try {
            jsonInString = mapper.writeValueAsString(kafkaOrderDto);
        } catch(JsonProcessingException ex) {
            ex.printStackTrace();
        }

        kafkaTemplate.send(topic, jsonInString);
        log.info("Order Producer sent data from the Order microservice: " + kafkaOrderDto);

        return orderDto;
    }
}
```

## 🗂 `controller`
### `OrderController.java`
```java
@RestController
@RequestMapping("/order-service")
public class OrderController {
    ...
    @PostMapping("/{userId}/orders")
    public ResponseEntity<ResponseOrder> createOrder(@PathVariable("userId") String userId, @RequestBody RequestOrder requestOrder) {
        ModelMapper mapper = new ModelMapper();
        mapper.getConfiguration().setMatchingStrategy(MatchingStrategies.STRICT);

        OrderDto orderDto = mapper.map(requestOrder, OrderDto.class);
        orderDto.setUserId(userId);

        /* jpa */
        // OrderDto createdOrder = orderService.createOrder(orderDto);
        // ResponseOrder responseOrder = mapper.map(createdOrder, ResponseOrder.class);

        /* 🌟 kafka */
        orderDto.setOrderId(UUID.randomUUID().toString());
        orderDto.setTotalPrice(requestOrder.getQty() * requestOrder.getUnitPrice());

        /* send this order to the kafka */
        kafkaProducer.send("example-catalog-topic", orderDto); // 토픽 이름은 catalog-service 의 KafkaConsumer 에서 확인할 수 있다.
        orderProducer.send("orders", orderDto); // 🌟 아래에서 orders 라는 이름의 sink connector를 새로 등록할 것이다.

        ResponseOrder responseOrder = mapper.map(orderDto, ResponseOrder.class);

        return ResponseEntity.status(HttpStatus.CREATED).body(responseOrder);
    }
}

```

# Sink Connector 추가
## 서버 기동
아래 서버들을 먼저 기동하자.
- zookeeper 서버
- kafka 서버

그리고 kafka connect 서버를 기동한다.
```bash
# 현재 위치: /Users/minju/study/msa/kafka-demo/confluent-6.1.0
$ ./bin/connect-distributed ./etc/kafka/connect-distributed.properties
```

## 현재 등록되어진 Connector 확인
![스크린샷 2022-10-12 오전 12 33 57](https://user-images.githubusercontent.com/59405576/195135586-58a96003-5105-4b37-8f03-b8e3fe30a80b.png)

## 새로운 Sink Connector 등록
![스크린샷 2022-10-12 오전 12 35 56](https://user-images.githubusercontent.com/59405576/195136124-3a1de966-0635-42b2-9bb7-0ab9c1ef0dba.png)
```json
{
  "name":"my-order-sink-connect",
  "config":{
  "connector.class":"io.confluent.connect.jdbc.JdbcSinkConnector",
  "connection.url":"jdbc:mysql://localhost:3306/mydb",
  "connection.user":"***",
  "connection.password":"***",
  "auto.create":"true",
  "auto.evolve":"true",
  "delete.enabled":"false",
  "tasks.max":"1",
  "topics":"orders"
  }
}
```
등록 후, 다시 connector 목록을 확인해보자.<br>
![스크린샷 2022-10-12 오전 12 40 02](https://user-images.githubusercontent.com/59405576/195137150-456b962e-13d7-4e60-b671-b4726fef0dd4.png)<br><br>
이제 여러 개의 `order-service`에서 발생했던 메시지가 토픽에 잘 전달되는지와<br>
전달된 데이터가 하나의 단일 데이터베이스에 들어가는지 테스트해보자.









***
<br>


    💛 개인 공부 기록용 블로그입니다. 👻

[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}