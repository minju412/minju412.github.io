---
title:  "[E-commerce App] Apache Kafka 사용(Kafka Connect) "

categories:
  - SpringCloud
tags:
  - [SpringCloud]

toc: true
toc_sticky: true
 
date: 2022-10-09 17:26:13
last_modified_at: 2022-10-09 17:26:16
---

이 전 글에는 Kafka를 이용해 Producer와 Consumer를 사용해보았다.<br>
이번에는 이어서 Kafka Connect를 사용해보자.<br><br>
데이터베이스에 저장된 값을 또다른 데이터베이스에 이동하는 예제를 테스트해보기 위해, MariaDB부터 설치하자.

# MariaDB 
## 설치 및 테이블 생성
위 명령어로 mariadb 설치 후 시작해보자.
```bash
# mariadb 설치
$ brew install mariadb

# 시작
$ mysql.server start

# 종료
$ mysql.server stop

# 상태 확인
$ mysql.server status
```
이제 mysql 접속해보자.<br>
접속할 때 username은 내가 따로 변경했기 때문에 `admin`으로 지정한 것이다. 보통은 `root`일 것이다.
```bash
# 접속
$ mysql -u admin -p

# 현재 어떤 데이터베이스(스키마)들이 있는지 확인
$ show databases;
```
접속했으면, `mydb`라는 이름의 데이터베이스를 새로 생성하자.<br>
`mydb`가 가지고 있는 테이블들을 확인해보면, 아직 아무것도 없을 것이다.
```bash
# 데이터베이스 생성
mysql> create database mydb;

# 방금 생성한 mydb 사용
mysql> use mydb;

# 현재 사용 중인 데이터베이스가 가지고 있는 테이블들 확인
mysql> show tables;
```
![스크린샷 2022-10-09 오후 6 05 45](https://user-images.githubusercontent.com/59405576/194748017-11968149-52a3-4807-85b5-2a7cc5f0843f.png)

## `order-service`
`order-service`에서 기존에 사용하던 h2 데이터베이스 대신, MariaDB를 연동해보자.

### `pom.xml`
```xml
<!-- MariaDB -->
<dependency>
    <groupId>org.mariadb.jdbc</groupId>
    <artifactId>mariadb-java-client</artifactId>
    <version>2.7.2</version>
</dependency>
```

이제 `user-service`를 기동해보자. <br>
(유레카 서버->`config-service`->`gateway-service`->`order-service` 순으로 기동되어 있어야 한다.)

## h2-console 접속
유레카 서버에 들어가서 `order-service`의 포트 번호 뒤를 `/h2-console`로 바꿔 h2 콘솔에 접속해보자.<br>
그럼 기존에 아래 사진처럼 되어있을텐데, 그 아래 사진처럼 변경하자.<br><br>
변경 전<br>
![스크린샷 2022-10-09 오후 6 17 09](https://user-images.githubusercontent.com/59405576/194748550-facbddad-40d0-4efb-9e45-5e2d8a18241d.png)<br><br>
변경 후<br>
![스크린샷 2022-10-09 오후 6 22 06](https://user-images.githubusercontent.com/59405576/194748767-5812aa4b-d27f-46bf-b74b-0938a59258a9.png)
```
Saved Settings: Generic MySQL
Setting Name: Generic MySQL

Driver Class: org.mariadb.jdbc.Driver
JDVC URL: jdbc:mysql://localhost:3306/mydb
User Name: admin    # 본인이 설정한 username
Password: ***    # 본인이 설정한 password
```

### 테이블 생성
아래 쿼리문으로 `users` 테이블을 생성해보자.
```
create table users(
    id int auto_increment primary key,
    user_id varchar(20),
    pwd varchar(20),
    name varchar(20),
    created_at datetime default NOW()
);
```
우리가 Kafka Connect를 통해 하고싶은 작업은,<br>
`users` 테이블에 새로운 데이터가 insert 될 때,<br>
그 데이터를 감지했다가, 고스란히 새로운 데이터베이스에 옮기는 것이다.<br><br>
이어서 `orders` 테이블을 생성해보자.
```
create table orders (
    id int auto_increment primary key,
    product_id varchar(20) not null,
    qty int default 0,
    unit_price int default 0,
    total_price int default 0,
    user_id varchar(50) not null,
    order_id varchar(50) not null,
    created_at datetime default NOW()
);
```

# Apache Kafka 사용
## Ecosystem - 2. Kafka Connect
- Kafka Connect를 통해 Data를 Import/Export 가능
- 프로기래밍 없이 Configuration 파일만으로 받아온 데이터를 다른쪽으로 이동 가능
- Standalone mode, Distribution mode 지원<br>- RESTful API를 통해 지원<br>- Stream 또는 Batch 형태로 데이터 전송 가능<br>- 커스텀 Connector를 통한 다양한 Plugin 제공 (File, S3, Hive, Mysql, etc ...)
- 데이터를 가져오는 쪽을 Connect Source라 하고, 데이터를 받는 쪽을 Connect Sink라 한다.

![스크린샷 2022-10-09 오후 5 24 09](https://user-images.githubusercontent.com/59405576/194746060-af7bd461-a1e0-4d15-a4ec-668d55a930de.png){: width="700" height="700"}

### Kafka Connect 설치 및 실행
```bash
# Kafka Connect 설치
$ curl -O http://packages.confluent.io/archive/6.1/confluent-community-6.1.0.tar.gz

# 압축 해제
$ tar xvf confluent-community-6.1.0.tar.gz

# 압축 해제한 디렉토리로 이동
$ cd confluent-6.1.0
```
![스크린샷 2022-10-09 오후 7 28 42](https://user-images.githubusercontent.com/59405576/194751764-f3c29503-ef7b-480a-bf8d-d5eb35e70795.png)


이제 Kafka Connect를 실행할건데, 그 전에 zookeeper 서버와 kafka 서버가 기동되고 있어야 한다!
```bash
# Kafka Connect 실행
$ ./bin/connect-distributed ./etc/kafka/connect-distributed.properties
```
Kafka Connect를 실행하기 전에 kafka 서버에서 토픽 리스트를 조회하고,<br>
Kafka Connect를 실행한 뒤에 kafka 서버에서 토픽 리스트를 조회해보면 아래와 같다.<br>
![스크린샷 2022-10-09 오후 7 41 46](https://user-images.githubusercontent.com/59405576/194752254-771ad191-3b10-46c4-998e-11400442481b.png)<br>
이 때 새로 생긴 것들은, <br>
kafka connect가 source에서 읽어온 데이터들을 관리하기 위한 토픽들이며, kafka connect를 실행함으로써 자동으로 생긴 것이다.

### JDBC Connector
Kafka Connect를 통해 한쪽에서 데이터를 읽어와서 다른쪽으로 전달하기 위해서 관계형 데이터베이스를 사용할 것이다.<br>
java에서 관계형 데이터베이스를 사용하기 위해서는 JDBC 라이브러리를 이용해야 한다.<br>
마찬가지로 Kafka Connect에서도 사용하려고 하는 소스에 맞는 JDBC Connector라는 것을 설치해야 한다.

#### 1) JDBC Connector 설치
[https://docs.confluent.io/5.5.1/connect/kafka-connect-jdbc/index.html](https://docs.confluent.io/5.5.1/connect/kafka-connect-jdbc/index.html)<br>
위 사이트에 들어가 아래 사진에 보이는 `Download and extract the ZIP file`을 클릭한 뒤, `Downlod` 한다.<br>
![스크린샷 2022-10-09 오후 7 06 49](https://user-images.githubusercontent.com/59405576/194750715-d4a460e4-04e1-4a6d-89d7-a7a945ffa2b6.png)<br><br>
그리고 다운받은 압축파일을 kafka가 있는 작업 디렉토리로 이동한다. (탐색기에서 이동해도 상관없다.)
```bash
# 압축파일이 저장된 위치로 이동
$ cd Downloads

# 압축파일을 작업 디렉토리로 이동
$ mv confluentinc-kafka-connect-jdbc-10.5.4.zip ~/study/msa/kafka-demo

# 압축 해제
$ tar xvf confluentinc-kafka-connect-jdbc-10.5.4.zip

# lib 안에 kafka-connect-jdbc-10.5.4.jar 파일이 위치해있다.
$ cd confluentinc-kafka-connect-jdbc-10.5.4/lib/

# 현재 위치를 읽어오기
$ pwd
```
![스크린샷 2022-10-09 오후 8 12 18](https://user-images.githubusercontent.com/59405576/194753704-e02ab6d2-2203-463f-9ba4-8f6a551ef5df.png)<br><br>
![스크린샷 2022-10-09 오후 8 17 30](https://user-images.githubusercontent.com/59405576/194753901-d040ffb7-f462-4087-8b53-46c62ee753a0.png)<br>
`kafka-connect-jdbc-10.5.4.jar` 파일이 우리가 필요한 파일이다.<br>
`pwd` 커맨드를 통해 해당 파일의 경로를 복사한다.

#### 2) JDBC Connector 연동
이제 설정파일을 바꿀 것이기 때문에 Kafka Connect는 `ctrl`+`c`로 잠시 중지하자.<br>
그리고 JDBC Connector를 연동하기 위해서 vim 또는 code를 통해 `etc/kafka/connect-distributed.properties` 파일을 수정할 것이다.<br>
```bash
$ code ./etc/kafka/connect-distributed.properties
```
![스크린샷 2022-10-09 오후 8 23 14](https://user-images.githubusercontent.com/59405576/194754126-238493cd-4a1f-4993-ae6b-810b3a238ccf.png)<br><br>
`etc/kafka/connect-distributed.properties` 파일 맨 아래 `plugin.path`에 이전에 `pwd`로 확인한 경로를 적어주면 된다.<br><br>
변경 전<br>
<img width="769" alt="스크린샷 2022-10-09 오후 8 21 30" src="https://user-images.githubusercontent.com/59405576/194754054-be14293b-d5bc-400b-932b-ba1a96766a9a.png"><br><br>
변경 후<br>
<img width="765" alt="스크린샷 2022-10-09 오후 8 21 55" src="https://user-images.githubusercontent.com/59405576/194754065-1161c596-699f-4385-afa0-6c011b5887a1.png">


#### 3) JdbcSourceConnector에서 MariaDB 사용
마지막으로, JdbcSourceConnector에서 MariaDB를 사용하기 위해 mariadb 드라이버를 복사한다.<br>
- `./share/java/kafka/` 폴더에 `mariadb-java-client-2.7.2.jar` 파일 복사

```bash
# 홈 디렉토리로 이동
$ cd

$ cd .m2/repository/org/mariadb/jdbc/mariadb-java-client/2.7.2

$ cp ./mariadb-java-client-2.7.2.jar /Users/minju/study/msa/kafka-demo/confluent-6.1.0/share/java/kafka
```

아래 사진에 보이는 `mariadb-java-client-2.7.2.jar` 파일을 kafka connect 디렉토리(= `confluent-6.1.0`) 안에 있는 `/share/java/kafka/`에 복사할 것이다.<br>
![스크린샷 2022-10-09 오후 8 29 25](https://user-images.githubusercontent.com/59405576/194754406-42826e34-5bb5-4ad2-8e8d-1aa064aafe04.png)<br><br>
`cp` 커맨드 실행 후, 정상적으로 copy가 되었는지 확인해보자.<br>
![스크린샷 2022-10-09 오후 8 35 02](https://user-images.githubusercontent.com/59405576/194754666-eb23a01b-585c-41cb-97bb-0fe2b4406c44.png)<br>
아래 사진을 보면, 정상적으로 copy가 되었음을 확인할 수 있다.<br>
![스크린샷 2022-10-09 오후 8 35 16](https://user-images.githubusercontent.com/59405576/194754670-7c41d9c1-a131-46a9-a563-b2f1bfa79c11.png)






***
<br>


    💛 개인 공부 기록용 블로그입니다. 👻

[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}